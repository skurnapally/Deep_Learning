{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "understanding_TimeDistributedLayer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP20oxQli0p5zSuV/XqcKN6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AtrCheema/Miscellaneous_DL_Tutorials/blob/master/understanding_TimeDistributedLayer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hjn-iXCUFZl"
      },
      "source": [
        "# simple `Conv1D`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsQkMY6RRsAX",
        "outputId": "add75a18-a0db-43af-f062-e4b64bc5d3a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, TimeDistributed, Conv1D, LSTM, MaxPool1D\n",
        "import numpy as np\n",
        "\n",
        "def reset_seed(seed=313):\n",
        "    tf.keras.backend.clear_session()\n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "np.set_printoptions(linewidth=150)\n",
        "\n",
        "print(tf.__version__, np.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0 1.18.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc_gMUGvj6o2",
        "outputId": "d2bc5d26-4584-4e36-a92d-a5b13ce32667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "input_features = 3\n",
        "lookback = 6\n",
        "batch_size=2\n",
        "input_shape = lookback,input_features\n",
        "ins = Input(shape=input_shape, name='my_input')\n",
        "outs = Conv1D(filters=8, kernel_size=3,\n",
        "              strides=1, padding='same', kernel_initializer='ones',\n",
        "              name='my_conv1d')(ins)\n",
        "model = Model(inputs=ins, outputs=outs)\n",
        "\n",
        "input_array = np.arange(36).reshape((batch_size, *input_shape))\n",
        "conv1d_weights = model.get_layer('my_conv1d').weights[0].numpy() \n",
        "output_array = model.predict(input_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fab469917b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD91JQ1AmYkN",
        "outputId": "ba905a18-06d5-4dba-ca95-6019f7e713dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "input_array, input_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[ 0,  1,  2],\n",
              "         [ 3,  4,  5],\n",
              "         [ 6,  7,  8],\n",
              "         [ 9, 10, 11],\n",
              "         [12, 13, 14],\n",
              "         [15, 16, 17]],\n",
              " \n",
              "        [[18, 19, 20],\n",
              "         [21, 22, 23],\n",
              "         [24, 25, 26],\n",
              "         [27, 28, 29],\n",
              "         [30, 31, 32],\n",
              "         [33, 34, 35]]]), (2, 6, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odYkzsupmcnU",
        "outputId": "4ebaabb1-e9a1-42e1-95ac-eea0863e3452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "conv1d_weights, conv1d_weights.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
              " \n",
              "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
              " \n",
              "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.]]], dtype=float32), (3, 3, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6tmNps4miFH",
        "outputId": "530dce13-5ae6-40c4-e9b4-0898ba84bdd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "output_array, output_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[ 15.,  15.,  15.,  15.,  15.,  15.,  15.,  15.],\n",
              "         [ 36.,  36.,  36.,  36.,  36.,  36.,  36.,  36.],\n",
              "         [ 63.,  63.,  63.,  63.,  63.,  63.,  63.,  63.],\n",
              "         [ 90.,  90.,  90.,  90.,  90.,  90.,  90.,  90.],\n",
              "         [117., 117., 117., 117., 117., 117., 117., 117.],\n",
              "         [ 87.,  87.,  87.,  87.,  87.,  87.,  87.,  87.]],\n",
              " \n",
              "        [[123., 123., 123., 123., 123., 123., 123., 123.],\n",
              "         [198., 198., 198., 198., 198., 198., 198., 198.],\n",
              "         [225., 225., 225., 225., 225., 225., 225., 225.],\n",
              "         [252., 252., 252., 252., 252., 252., 252., 252.],\n",
              "         [279., 279., 279., 279., 279., 279., 279., 279.],\n",
              "         [195., 195., 195., 195., 195., 195., 195., 195.]]], dtype=float32),\n",
              " (2, 6, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnTPtCK1DFqy"
      },
      "source": [
        "# multiple inputs multiple layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o9x1HdUa_Cw"
      },
      "source": [
        "\n",
        "input_features = 3\n",
        "lookback = 3\n",
        "batch_size=2\n",
        "input_shape = lookback,input_features\n",
        "ins1 = Input(shape=input_shape, name='my_input1')\n",
        "ins2 = Input(shape=input_shape, name='my_input2')\n",
        "outs1 = Conv1D(filters=8, kernel_size=3,\n",
        "              strides=1, padding='same', kernel_initializer='ones',\n",
        "              name='my_conv1d1')(ins1)\n",
        "outs2 = Conv1D(filters=8, kernel_size=3,\n",
        "              strides=1, padding='same', kernel_initializer='ones',\n",
        "              name='my_conv1d2')(ins2)\n",
        "model = Model(inputs=[ins1, ins2], outputs=[outs1, outs2])\n",
        "\n",
        "sub_seq = 2\n",
        "input_shape = sub_seq, 3, input_features\n",
        "input_array = np.arange(36).reshape((batch_size, *input_shape))\n",
        "input_array1 = input_array[:, 0, :, :]\n",
        "input_array2 = input_array[:, 1, :, :]\n",
        "\n",
        "conv1d1_weights = model.get_layer('my_conv1d1').weights[0].numpy()\n",
        "conv1d2_weights = model.get_layer('my_conv1d2').weights[0].numpy()\n",
        "output_array = model.predict([input_array1, input_array2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLOEy1X9bwX6",
        "outputId": "4a5b40db-0344-4b2e-9a40-cffba2b10f28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "print(input_array1, '\\n\\n', input_array2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 0  1  2]\n",
            "  [ 3  4  5]\n",
            "  [ 6  7  8]]\n",
            "\n",
            " [[18 19 20]\n",
            "  [21 22 23]\n",
            "  [24 25 26]]] \n",
            "\n",
            " [[[ 9 10 11]\n",
            "  [12 13 14]\n",
            "  [15 16 17]]\n",
            "\n",
            " [[27 28 29]\n",
            "  [30 31 32]\n",
            "  [33 34 35]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw7f3ngobyir",
        "outputId": "11fa6754-3613-4a8b-d72b-07c0a953d314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "conv1d2_weights, conv1d2_weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
              " \n",
              "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
              " \n",
              "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.]]], dtype=float32),\n",
              " array([[[1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
              " \n",
              "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
              " \n",
              "        [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1.]]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNR7yFeUe3xa",
        "outputId": "ec0d6681-ca7d-4cb1-fefa-465c7bbaca5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "output_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[ 15.,  15.,  15.,  15.,  15.,  15.,  15.,  15.],\n",
              "         [ 36.,  36.,  36.,  36.,  36.,  36.,  36.,  36.],\n",
              "         [ 33.,  33.,  33.,  33.,  33.,  33.,  33.,  33.]],\n",
              " \n",
              "        [[123., 123., 123., 123., 123., 123., 123., 123.],\n",
              "         [198., 198., 198., 198., 198., 198., 198., 198.],\n",
              "         [141., 141., 141., 141., 141., 141., 141., 141.]]], dtype=float32),\n",
              " array([[[ 69.,  69.,  69.,  69.,  69.,  69.,  69.,  69.],\n",
              "         [117., 117., 117., 117., 117., 117., 117., 117.],\n",
              "         [ 87.,  87.,  87.,  87.,  87.,  87.,  87.,  87.]],\n",
              " \n",
              "        [[177., 177., 177., 177., 177., 177., 177., 177.],\n",
              "         [279., 279., 279., 279., 279., 279., 279., 279.],\n",
              "         [195., 195., 195., 195., 195., 195., 195., 195.]]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiVRUX5YDL9y"
      },
      "source": [
        "# multiple inputs shared layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7w-kZv1b04k"
      },
      "source": [
        "\n",
        "input_features = 3\n",
        "lookback = 6\n",
        "sub_seq = 2\n",
        "input_shape = sub_seq, 3, input_features\n",
        "batch_size = 2\n",
        "\n",
        "ins = Input(shape=input_shape, name='my_input')\n",
        "conv = Conv1D(filters=8, kernel_size=3,\n",
        "              strides=1, padding='same',\n",
        "              kernel_initializer='ones', name='my_conv1d')\n",
        "\n",
        "conv1_out = conv(ins[:, 0, :, :])\n",
        "conv2_out = conv(ins[:, 1, :, :])\n",
        "model = Model(inputs=ins, outputs=[conv1_out, conv2_out])\n",
        "\n",
        "input_array = np.arange(36).reshape((batch_size, *input_shape))\n",
        "conv1d_weights = model.get_layer('my_conv1d').weights[0].numpy()\n",
        "output_array = model.predict(input_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkaWWj2H_Yuz",
        "outputId": "53edd1c4-b91f-42c4-c9ce-d0e63f534370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "input_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 0,  1,  2],\n",
              "         [ 3,  4,  5],\n",
              "         [ 6,  7,  8]],\n",
              "\n",
              "        [[ 9, 10, 11],\n",
              "         [12, 13, 14],\n",
              "         [15, 16, 17]]],\n",
              "\n",
              "\n",
              "       [[[18, 19, 20],\n",
              "         [21, 22, 23],\n",
              "         [24, 25, 26]],\n",
              "\n",
              "        [[27, 28, 29],\n",
              "         [30, 31, 32],\n",
              "         [33, 34, 35]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-X3sjw1BT9L",
        "outputId": "67e2e9b6-de27-4372-9d01-b9dbc61b2f27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "conv1d_weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
              "\n",
              "       [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]],\n",
              "\n",
              "       [[1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpUS3ULKAEUb",
        "outputId": "88026277-3c93-41db-a859-3c3dc5b5ce66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "output_array[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 15.,  15.,  15.,  15.,  15.,  15.,  15.,  15.],\n",
              "        [ 36.,  36.,  36.,  36.,  36.,  36.,  36.,  36.],\n",
              "        [ 33.,  33.,  33.,  33.,  33.,  33.,  33.,  33.]],\n",
              "\n",
              "       [[123., 123., 123., 123., 123., 123., 123., 123.],\n",
              "        [198., 198., 198., 198., 198., 198., 198., 198.],\n",
              "        [141., 141., 141., 141., 141., 141., 141., 141.]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmM4ZOz1uySU",
        "outputId": "24c296c2-6499-4e6e-8c4b-9c6bd5877724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "output_array[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 69.,  69.,  69.,  69.,  69.,  69.,  69.,  69.],\n",
              "        [117., 117., 117., 117., 117., 117., 117., 117.],\n",
              "        [ 87.,  87.,  87.,  87.,  87.,  87.,  87.,  87.]],\n",
              "\n",
              "       [[177., 177., 177., 177., 177., 177., 177., 177.],\n",
              "        [279., 279., 279., 279., 279., 279., 279., 279.],\n",
              "        [195., 195., 195., 195., 195., 195., 195., 195.]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pMN8lKEUMWt"
      },
      "source": [
        "# `TimeDistributed Conv1D`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJqnf_mDB1nk"
      },
      "source": [
        "\n",
        "input_features = 3\n",
        "lookback = 6\n",
        "sub_seq = 2\n",
        "input_shape = sub_seq, 3, input_features\n",
        "batch_size = 2\n",
        "\n",
        "ins = Input(shape=input_shape, name='my_input')\n",
        "outs = TimeDistributed(Conv1D(filters=8, kernel_size=3,\n",
        "              strides=1, padding='same', kernel_initializer='ones', \n",
        "              name='my_conv1d'))(ins)\n",
        "model = Model(inputs=ins, outputs=outs)\n",
        "\n",
        "input_array = np.arange(36).reshape((batch_size, *input_shape))\n",
        "output_array = model.predict(input_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfB81gG5CMsy",
        "outputId": "531e62a7-6e4f-432c-e843-8df803caa093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "input_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 0,  1,  2],\n",
              "         [ 3,  4,  5],\n",
              "         [ 6,  7,  8]],\n",
              "\n",
              "        [[ 9, 10, 11],\n",
              "         [12, 13, 14],\n",
              "         [15, 16, 17]]],\n",
              "\n",
              "\n",
              "       [[[18, 19, 20],\n",
              "         [21, 22, 23],\n",
              "         [24, 25, 26]],\n",
              "\n",
              "        [[27, 28, 29],\n",
              "         [30, 31, 32],\n",
              "         [33, 34, 35]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ACwQMK5CO-U",
        "outputId": "aba7ab85-e8e3-46d7-a20f-95d65ed32b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "output_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 15.,  15.,  15.,  15.,  15.,  15.,  15.,  15.],\n",
              "         [ 36.,  36.,  36.,  36.,  36.,  36.,  36.,  36.],\n",
              "         [ 33.,  33.,  33.,  33.,  33.,  33.,  33.,  33.]],\n",
              "\n",
              "        [[ 69.,  69.,  69.,  69.,  69.,  69.,  69.,  69.],\n",
              "         [117., 117., 117., 117., 117., 117., 117., 117.],\n",
              "         [ 87.,  87.,  87.,  87.,  87.,  87.,  87.,  87.]]],\n",
              "\n",
              "\n",
              "       [[[123., 123., 123., 123., 123., 123., 123., 123.],\n",
              "         [198., 198., 198., 198., 198., 198., 198., 198.],\n",
              "         [141., 141., 141., 141., 141., 141., 141., 141.]],\n",
              "\n",
              "        [[177., 177., 177., 177., 177., 177., 177., 177.],\n",
              "         [279., 279., 279., 279., 279., 279., 279., 279.],\n",
              "         [195., 195., 195., 195., 195., 195., 195., 195.]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM0blnzDIfAL"
      },
      "source": [
        "So `TimeDistributed` Just applies same `Conv1D` to each sub-sequence/incoming input.\n",
        "\n",
        "# `TimeDistributed` `LSTM`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIllkM8NE4q7",
        "outputId": "f3cab5a5-26e5-4cd3-9cee-41d247bb83df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\n",
        "tf.random.set_seed(313) \n",
        "\n",
        "input_features = 3\n",
        "sub_seq = 2\n",
        "input_shape = sub_seq, 3, input_features\n",
        "batch_size = 2\n",
        "\n",
        "ins = Input(shape=input_shape, name='my_input')\n",
        "outs = TimeDistributed(LSTM(units=8, name='my_lstm'))(ins)\n",
        "model = Model(inputs=ins, outputs=outs)\n",
        "\n",
        "input_array = np.arange(36).reshape((batch_size, *input_shape))\n",
        "output_array = model.predict(input_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fab44cc8a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SES9y9kVFtrI",
        "outputId": "69a31c4d-7b75-4e0a-8d98-cdc2e644c3d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "input_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 0,  1,  2],\n",
              "         [ 3,  4,  5],\n",
              "         [ 6,  7,  8]],\n",
              "\n",
              "        [[ 9, 10, 11],\n",
              "         [12, 13, 14],\n",
              "         [15, 16, 17]]],\n",
              "\n",
              "\n",
              "       [[[18, 19, 20],\n",
              "         [21, 22, 23],\n",
              "         [24, 25, 26]],\n",
              "\n",
              "        [[27, 28, 29],\n",
              "         [30, 31, 32],\n",
              "         [33, 34, 35]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqGyzpbiFvzz",
        "outputId": "7b51745a-791e-4064-88a4-d59e1f9f3d9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "output_array[:, 0, :]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.6062409e-01,  2.2913465e-01,  1.0585530e-01,  6.0561293e-01, -3.6559592e-03, -1.4262524e-01,  9.5918020e-03,  2.6522632e-04],\n",
              "       [-1.3387868e-03,  1.6973073e-02,  1.3584232e-02,  2.4525641e-01, -5.3840652e-09, -1.3385731e-03,  9.8304715e-09,  1.6285184e-13]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVjk5WkCKkW_",
        "outputId": "50be65c9-f0f5-4b16-abd3-321796f9a77e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "output_array[:, 1, :]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.6962688e-02,  6.4336620e-02,  6.8063535e-02,  5.8035445e-01, -4.6160312e-06, -1.3993834e-02,  1.5005664e-05,  6.2304650e-09],\n",
              "       [-1.0763946e-04,  4.2649782e-03,  2.5343844e-03,  8.0139175e-02, -6.2821484e-12, -1.3424609e-04,  5.9522946e-12,  4.1778258e-18]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_VQ9YGRIVUF"
      },
      "source": [
        "# manual weight sharing of `LSTM`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5UqMX8GG1pS",
        "outputId": "551e5d23-4eac-484c-d440-6fa07cbe46de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\n",
        "tf.random.set_seed(313) \n",
        "\n",
        "input_features = 3\n",
        "sub_seq = 2\n",
        "input_shape = sub_seq, 3, input_features\n",
        "batch_size = 2\n",
        "\n",
        "ins = Input(shape=input_shape, name='my_input')\n",
        "lstm = LSTM(units=8, name='my_lstm')\n",
        "\n",
        "lstm1_out = lstm(ins[:, 0, :, :])\n",
        "lstm2_out = lstm(ins[:, 1, :, :])\n",
        "model = Model(inputs=ins, outputs=[lstm1_out, lstm2_out])\n",
        "\n",
        "input_array = np.arange(36).reshape((batch_size, *input_shape))\n",
        "output_array = model.predict(input_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fab46fb7bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE9TPZzFHTiq",
        "outputId": "fbdcdc8c-ac61-44d1-d583-653bb0f79cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "input_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 0,  1,  2],\n",
              "         [ 3,  4,  5],\n",
              "         [ 6,  7,  8]],\n",
              "\n",
              "        [[ 9, 10, 11],\n",
              "         [12, 13, 14],\n",
              "         [15, 16, 17]]],\n",
              "\n",
              "\n",
              "       [[[18, 19, 20],\n",
              "         [21, 22, 23],\n",
              "         [24, 25, 26]],\n",
              "\n",
              "        [[27, 28, 29],\n",
              "         [30, 31, 32],\n",
              "         [33, 34, 35]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "senUXIz1HVdJ",
        "outputId": "9fa54085-4676-4aa5-9e3e-ac6796343647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "output_array[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.6062410e-01,  2.2913465e-01,  1.0585530e-01,  6.0561293e-01, -3.6559592e-03, -1.4262524e-01,  9.5918020e-03,  2.6522632e-04],\n",
              "       [-1.3387636e-03,  1.6973050e-02,  1.3584232e-02,  2.4525636e-01, -5.3840639e-09, -1.3385731e-03,  9.8304707e-09,  1.6285168e-13]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJBFbSXPKhFp",
        "outputId": "c20ba919-fd5a-4da1-eb6e-d7280417371b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "output_array[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.6962737e-02,  6.4336628e-02,  6.8063594e-02,  5.8035445e-01, -4.6160267e-06, -1.3993834e-02,  1.5005662e-05,  6.2304650e-09],\n",
              "       [-1.0763946e-04,  4.2649782e-03,  2.5344139e-03,  8.0139175e-02, -6.2821367e-12, -1.3424607e-04,  5.9522842e-12,  4.1778180e-18]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "202VIOpggOfU"
      },
      "source": [
        "# Curious case of `Dense`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx4_Hrmnc7Ru",
        "outputId": "c2303b83-8edd-4962-a8ee-c3e718448484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\n",
        "tf.random.set_seed(313)\n",
        "\n",
        "input_features = 3\n",
        "lookback = 6\n",
        "batch_size=2\n",
        "input_shape = lookback,input_features\n",
        "\n",
        "input_shape = lookback, input_features\n",
        "ins = Input(input_shape, name='my_input')\n",
        "out = Dense(units=5,  name='my_output')(ins)\n",
        "model = Model(inputs=ins, outputs=out)\n",
        "\n",
        "input_array = np.arange(36).reshape(batch_size, *input_shape)\n",
        "output_array = model.predict(input_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fab46d1f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xVS4JFQgoRL",
        "outputId": "349a3015-e63a-48e6-ba7c-d8f3345bce74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "input_array, input_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[ 0,  1,  2],\n",
              "         [ 3,  4,  5],\n",
              "         [ 6,  7,  8],\n",
              "         [ 9, 10, 11],\n",
              "         [12, 13, 14],\n",
              "         [15, 16, 17]],\n",
              " \n",
              "        [[18, 19, 20],\n",
              "         [21, 22, 23],\n",
              "         [24, 25, 26],\n",
              "         [27, 28, 29],\n",
              "         [30, 31, 32],\n",
              "         [33, 34, 35]]]), (2, 6, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjMKCjNOgtYT",
        "outputId": "ed7665dd-0008-4bc0-d376-111922994464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "output_array, output_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[  0.27596885,   0.70854443,  -0.53744566,  -0.70061463,  -0.20640421],\n",
              "         [  0.36203665,   3.999878  ,  -1.7514435 ,  -2.695434  ,   0.17058378],\n",
              "         [  0.44810438,   7.291211  ,  -2.9654412 ,  -4.6902533 ,   0.5475718 ],\n",
              "         [  0.53417236,  10.582545  ,  -4.179439  ,  -6.685073  ,   0.92456   ],\n",
              "         [  0.62023985,  13.8738785 ,  -5.393437  ,  -8.679893  ,   1.3015479 ],\n",
              "         [  0.7063078 ,  17.165213  ,  -6.607435  , -10.674712  ,   1.6785362 ]],\n",
              " \n",
              "        [[  0.7923758 ,  20.456545  ,  -7.821433  , -12.669531  ,   2.055524  ],\n",
              "         [  0.8784433 ,  23.747879  ,  -9.035431  , -14.664351  ,   2.432512  ],\n",
              "         [  0.9645113 ,  27.039211  , -10.249429  , -16.65917   ,   2.8094997 ],\n",
              "         [  1.0505788 ,  30.330545  , -11.463427  , -18.65399   ,   3.1864882 ],\n",
              "         [  1.1366472 ,  33.62188   , -12.6774235 , -20.64881   ,   3.5634766 ],\n",
              "         [  1.2227151 ,  36.91321   , -13.891422  , -22.64363   ,   3.9404645 ]]], dtype=float32),\n",
              " (2, 6, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWhiuPQkhDvS",
        "outputId": "8fe5abe0-810f-4db9-e77d-872ea3f3d4c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\n",
        "tf.random.set_seed(313)\n",
        "\n",
        "input_features = 3\n",
        "lookback = 6\n",
        "sub_seq = 2\n",
        "input_shape = sub_seq, 3, input_features\n",
        "batch_size = 2\n",
        "\n",
        "ins = Input(input_shape, name='my_input')\n",
        "out = TimeDistributed(Dense(units=5, name='my_output'))(ins)\n",
        "model = Model(inputs=ins, outputs=out)\n",
        "\n",
        "\n",
        "input_array = np.arange(36).reshape(batch_size, *input_shape)\n",
        "output_array = model.predict(input_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fab46d031e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4FwmvhezugF",
        "outputId": "e1ecd5de-a1c3-41a5-a0e5-eb9fe0f3e4db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "input_array, input_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[[ 0,  1,  2],\n",
              "          [ 3,  4,  5],\n",
              "          [ 6,  7,  8]],\n",
              " \n",
              "         [[ 9, 10, 11],\n",
              "          [12, 13, 14],\n",
              "          [15, 16, 17]]],\n",
              " \n",
              " \n",
              "        [[[18, 19, 20],\n",
              "          [21, 22, 23],\n",
              "          [24, 25, 26]],\n",
              " \n",
              "         [[27, 28, 29],\n",
              "          [30, 31, 32],\n",
              "          [33, 34, 35]]]]), (2, 2, 3, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDWo9H9YiDbh",
        "outputId": "e63c52e1-e0bc-49cd-d058-7c56b84e07f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "output_array, output_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[[  0.27596885,   0.70854443,  -0.53744566,  -0.70061463,  -0.20640421],\n",
              "          [  0.36203665,   3.999878  ,  -1.7514435 ,  -2.695434  ,   0.17058378],\n",
              "          [  0.44810438,   7.291211  ,  -2.9654412 ,  -4.6902533 ,   0.5475718 ]],\n",
              " \n",
              "         [[  0.53417236,  10.582545  ,  -4.179439  ,  -6.685073  ,   0.92456   ],\n",
              "          [  0.62023985,  13.8738785 ,  -5.393437  ,  -8.679893  ,   1.3015479 ],\n",
              "          [  0.7063078 ,  17.165213  ,  -6.607435  , -10.674712  ,   1.6785362 ]]],\n",
              " \n",
              " \n",
              "        [[[  0.7923758 ,  20.456545  ,  -7.821433  , -12.669531  ,   2.055524  ],\n",
              "          [  0.8784433 ,  23.747879  ,  -9.035431  , -14.664351  ,   2.432512  ],\n",
              "          [  0.9645113 ,  27.039211  , -10.249429  , -16.65917   ,   2.8094997 ]],\n",
              " \n",
              "         [[  1.0505788 ,  30.330545  , -11.463427  , -18.65399   ,   3.1864882 ],\n",
              "          [  1.1366472 ,  33.62188   , -12.6774235 , -20.64881   ,   3.5634766 ],\n",
              "          [  1.2227151 ,  36.91321   , -13.891422  , -22.64363   ,   3.9404645 ]]]], dtype=float32),\n",
              " (2, 2, 3, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFLHKjo2iQVx"
      },
      "source": [
        "so far looks very similar to `TimeDistributed(Conv1D)` or `TimeDistributed(LSTM)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yta-kQHYie9o",
        "outputId": "f4965323-280a-4f29-87bf-5dc8534a91cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\n",
        "tf.random.set_seed(313)\n",
        "\n",
        "input_features = 3\n",
        "lookback = 6\n",
        "input_shape = lookback, input_features\n",
        "batch_size = 2\n",
        "\n",
        "ins = Input(input_shape, name='my_input')\n",
        "out = TimeDistributed(Dense(5, use_bias=False, name='my_output'))(ins)\n",
        "model = Model(inputs=ins, outputs=out)\n",
        "\n",
        "input_array = np.arange(36).reshape(batch_size, *input_shape)\n",
        "output_array = model.predict(input_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fab46d1fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjc0Da2o1B6c",
        "outputId": "756c6323-2643-4dc6-f2e2-081372e9cfa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "input_array, input_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[ 0,  1,  2],\n",
              "         [ 3,  4,  5],\n",
              "         [ 6,  7,  8],\n",
              "         [ 9, 10, 11],\n",
              "         [12, 13, 14],\n",
              "         [15, 16, 17]],\n",
              " \n",
              "        [[18, 19, 20],\n",
              "         [21, 22, 23],\n",
              "         [24, 25, 26],\n",
              "         [27, 28, 29],\n",
              "         [30, 31, 32],\n",
              "         [33, 34, 35]]]), (2, 6, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPewmaxMil-R",
        "outputId": "70e6b9ac-f971-46f4-c5f6-05a9d2570394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "output_array, output_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[  0.27596885,   0.70854443,  -0.53744566,  -0.70061463,  -0.20640421],\n",
              "         [  0.36203665,   3.999878  ,  -1.7514435 ,  -2.695434  ,   0.17058378],\n",
              "         [  0.44810438,   7.291211  ,  -2.9654412 ,  -4.6902533 ,   0.5475718 ],\n",
              "         [  0.53417236,  10.582545  ,  -4.179439  ,  -6.685073  ,   0.92456   ],\n",
              "         [  0.62023985,  13.8738785 ,  -5.393437  ,  -8.679893  ,   1.3015479 ],\n",
              "         [  0.7063078 ,  17.165213  ,  -6.607435  , -10.674712  ,   1.6785362 ]],\n",
              " \n",
              "        [[  0.7923758 ,  20.456545  ,  -7.821433  , -12.669531  ,   2.055524  ],\n",
              "         [  0.8784433 ,  23.747879  ,  -9.035431  , -14.664351  ,   2.432512  ],\n",
              "         [  0.9645113 ,  27.039211  , -10.249429  , -16.65917   ,   2.8094997 ],\n",
              "         [  1.0505788 ,  30.330545  , -11.463427  , -18.65399   ,   3.1864882 ],\n",
              "         [  1.1366472 ,  33.62188   , -12.6774235 , -20.64881   ,   3.5634766 ],\n",
              "         [  1.2227151 ,  36.91321   , -13.891422  , -22.64363   ,   3.9404645 ]]], dtype=float32),\n",
              " (2, 6, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSYs9fbHlq_9"
      },
      "source": [
        "So whether we we `TimeDistributed(Dense)` or `Dense`, they are actually equivalent.\n",
        "\n",
        "What if we try same with `Conv1D` or `LSTM` i.e. wrapping these layers in `TimeDistributed` without modifying/dividing input into sub-sequences?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wljgkqDLm5p0",
        "outputId": "d7498f4f-ea49-467c-bde7-a8581be79558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "\n",
        "input_features = 3\n",
        "lookback = 6\n",
        "input_shape = lookback, input_features\n",
        "ins = Input(shape=(lookback, input_features), name='my_input')\n",
        "outs = TimeDistributed(Conv1D(filters=8, kernel_size=3,\n",
        "              strides=1, padding='valid', kernel_initializer='ones',\n",
        "              name='my_conv1d'))(ins)\n",
        "model = Model(inputs=ins, outputs=outs)\n",
        "\n",
        "input_array = np.arange(36).reshape((batch_size, *input_shape))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-b0f0a504e058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m outs = TimeDistributed(Conv1D(filters=8, kernel_size=3,\n\u001b[1;32m      7\u001b[0m               \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ones'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m               name='my_conv1d'))(ins)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    235\u001b[0m           \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_mask_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Shape: (num_samples, timesteps, ...)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1090\u001b[0m       \u001b[0;31m# TODO(reedwm): We should assert input compatibility after the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m       \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Use `self._name_scope()` to avoid auto-incrementing the name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    194\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer my_conv1d is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: [None, 3]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQJyd3c9m_G9"
      },
      "source": [
        "The above error message can be slightly confusing or atleast can be resolved in a wrong manner as we do in following case;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf7zhOzNlqCO",
        "outputId": "b5626ea4-a961-4e25-b0d1-97a6a53dcc92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "input_features = 3\n",
        "lookback = 6\n",
        "input_shape = lookback, input_features\n",
        "ins = Input(shape=(batch_size, lookback, input_features), name='my_input')\n",
        "outs = TimeDistributed(Conv1D(filters=8, kernel_size=3,\n",
        "              strides=1, padding='valid', kernel_initializer='ones', \n",
        "              name='my_conv1d'))(ins)\n",
        "model = Model(inputs=ins, outputs=outs)\n",
        "\n",
        "input_array = np.arange(36).reshape((batch_size, *input_shape))\n",
        "print(input_array.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 6, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEW-hUT5n2Mj"
      },
      "source": [
        "So we are able to compile the model, although it is wrong. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8H5YW-hmwgE",
        "outputId": "046c3510-e2b1-4d2b-c26a-9e0319efdceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        }
      },
      "source": [
        "output_array = model.predict(input_array)\n",
        "print(output_array.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 2, 6, 3) for input Tensor(\"my_input_9:0\", shape=(None, 2, 6, 3), dtype=float32), but it was called on an input with incompatible shape (None, 6, 3).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-2cce97b642e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer time_distributed_5 is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [None, 6, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOvHlrqCn_Zd"
      },
      "source": [
        "This error message is exactly related to `TimeDistributed` layer. The `TimeDistributed` layer here expects input having 4 dimensions, 1st being batch size, second being the sub-sequences, 3rd being the time-steps or whatever and 4rth being number of input features here. \n",
        "\n",
        "Anyhow, the conclusion is, we can't just wrap layers in `TimeDistributed` except for `Dense` layer. Hence, using `TimeDistributed(Dense)` does not make any sense (to me until version 2.3.0)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKh3-beBi3UR"
      },
      "source": [
        "\n",
        "\n",
        "# More than just weight sharing\n",
        "\n",
        "`TimeDistributed` layer is meant to provide more functionality than just weight sharing. We see, pooling layers or flatten layers wrapped into `TimeDistributed` layer even though pooling layers or flattening layers don't have any weights. This is because if we have applied `TimeDistributed(Conv1D)`, this will sprout output for each sub-sequence. We would naturally like to apply pooling and consequently flattening layers to each output fo the sub-sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV7dREWDir_i",
        "outputId": "0e3be24c-d745-4221-bdd7-c404cbcd74c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\n",
        "input_features = 3\n",
        "sub_seq = 2\n",
        "input_shape = sub_seq, 3, input_features\n",
        "batch_size = 2\n",
        "\n",
        "ins = Input(shape=input_shape, name='my_input')\n",
        "conv_outs = TimeDistributed(Conv1D(filters=8, kernel_size=3,\n",
        "              strides=1,\n",
        "              padding='same',\n",
        "              kernel_initializer='ones', \n",
        "              name='my_conv1d'))(ins)\n",
        "outs = TimeDistributed(MaxPool1D(pool_size=2))(conv_outs)\n",
        "model = Model(inputs=ins, outputs=[outs, conv_outs])\n",
        "\n",
        "input_array = np.arange(36).reshape((batch_size, *input_shape))\n",
        "output_array, conv_output = model.predict(input_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fab46a12ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjQLHXWhc7TB",
        "outputId": "a3cdeb1d-ed65-4f04-f367-932b712e874c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "print(input_array.shape)\n",
        "input_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 2, 3, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 0,  1,  2],\n",
              "         [ 3,  4,  5],\n",
              "         [ 6,  7,  8]],\n",
              "\n",
              "        [[ 9, 10, 11],\n",
              "         [12, 13, 14],\n",
              "         [15, 16, 17]]],\n",
              "\n",
              "\n",
              "       [[[18, 19, 20],\n",
              "         [21, 22, 23],\n",
              "         [24, 25, 26]],\n",
              "\n",
              "        [[27, 28, 29],\n",
              "         [30, 31, 32],\n",
              "         [33, 34, 35]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoZvjv_ybgJg",
        "outputId": "a0e66804-b9e8-4cf2-e48c-dcf309702001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "conv_output, conv_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[[ 15.,  15.,  15.,  15.,  15.,  15.,  15.,  15.],\n",
              "          [ 36.,  36.,  36.,  36.,  36.,  36.,  36.,  36.],\n",
              "          [ 33.,  33.,  33.,  33.,  33.,  33.,  33.,  33.]],\n",
              " \n",
              "         [[ 69.,  69.,  69.,  69.,  69.,  69.,  69.,  69.],\n",
              "          [117., 117., 117., 117., 117., 117., 117., 117.],\n",
              "          [ 87.,  87.,  87.,  87.,  87.,  87.,  87.,  87.]]],\n",
              " \n",
              " \n",
              "        [[[123., 123., 123., 123., 123., 123., 123., 123.],\n",
              "          [198., 198., 198., 198., 198., 198., 198., 198.],\n",
              "          [141., 141., 141., 141., 141., 141., 141., 141.]],\n",
              " \n",
              "         [[177., 177., 177., 177., 177., 177., 177., 177.],\n",
              "          [279., 279., 279., 279., 279., 279., 279., 279.],\n",
              "          [195., 195., 195., 195., 195., 195., 195., 195.]]]], dtype=float32),\n",
              " (2, 2, 3, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5ObihiGqe_p",
        "outputId": "81101a64-60a6-4cb8-870f-2cb23346ea68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "output_array, output_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[[ 36.,  36.,  36.,  36.,  36.,  36.,  36.,  36.]],\n",
              " \n",
              "         [[117., 117., 117., 117., 117., 117., 117., 117.]]],\n",
              " \n",
              " \n",
              "        [[[198., 198., 198., 198., 198., 198., 198., 198.]],\n",
              " \n",
              "         [[279., 279., 279., 279., 279., 279., 279., 279.]]]], dtype=float32),\n",
              " (2, 2, 1, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FElgt5ntuY6e",
        "outputId": "4767a8ff-d0d8-4e58-d7e6-0beb667024d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\n",
        "input_features = 3\n",
        "sub_seq = 2\n",
        "input_shape = sub_seq, 3, input_features\n",
        "batch_size = 2\n",
        "\n",
        "ins = Input(shape=input_shape, name='my_input')\n",
        "conv_outs = TimeDistributed(Conv1D(filters=8, kernel_size=3,\n",
        "              strides=1, padding='same',\n",
        "              kernel_initializer='ones', \n",
        "              name='my_conv1d'))(ins)\n",
        "outs = TimeDistributed(MaxPool1D(pool_size=2, padding='same'))(conv_outs)\n",
        "model = Model(inputs=ins, outputs=outs)\n",
        "\n",
        "input_array = np.arange(36).reshape((batch_size, *input_shape))\n",
        "output_array = model.predict(input_array) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fab469eb510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om3C5ZiIeVci",
        "outputId": "61bf9e9c-61ad-481d-cebd-3e7dc850e90f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "input_array, input_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[[ 0,  1,  2],\n",
              "          [ 3,  4,  5],\n",
              "          [ 6,  7,  8]],\n",
              " \n",
              "         [[ 9, 10, 11],\n",
              "          [12, 13, 14],\n",
              "          [15, 16, 17]]],\n",
              " \n",
              " \n",
              "        [[[18, 19, 20],\n",
              "          [21, 22, 23],\n",
              "          [24, 25, 26]],\n",
              " \n",
              "         [[27, 28, 29],\n",
              "          [30, 31, 32],\n",
              "          [33, 34, 35]]]]), (2, 2, 3, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXRG0n9Uu_im",
        "outputId": "fd775a9e-dd38-431c-91b6-1f5a4116bf76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "output_array, output_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[[ 36.,  36.,  36.,  36.,  36.,  36.,  36.,  36.],\n",
              "          [ 33.,  33.,  33.,  33.,  33.,  33.,  33.,  33.]],\n",
              " \n",
              "         [[117., 117., 117., 117., 117., 117., 117., 117.],\n",
              "          [ 87.,  87.,  87.,  87.,  87.,  87.,  87.,  87.]]],\n",
              " \n",
              " \n",
              "        [[[198., 198., 198., 198., 198., 198., 198., 198.],\n",
              "          [141., 141., 141., 141., 141., 141., 141., 141.]],\n",
              " \n",
              "         [[279., 279., 279., 279., 279., 279., 279., 279.],\n",
              "          [195., 195., 195., 195., 195., 195., 195., 195.]]]], dtype=float32),\n",
              " (2, 2, 2, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEr6yrNLvA0F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}